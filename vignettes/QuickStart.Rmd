---
title: "gwasCatSearch Quick Start"
author: "Robert Gentleman"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{gwasCatSearch Quick Start}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
format: html
editor: visual
---

## Introduction

```{r echo=FALSE, warning=FALSE, message=FALSE}
library("gwasCatSearch")
library(DT)
```

The gwasCatSearch package provides functionality to search for different phenotypes within the GWAS catalog (<https://www.ebi.ac.uk/gwas/>) database. We used the mappings provided by the GWAS catalog for phenotypes to the EFO ontology (<https://www.ebi.ac.uk/efo/>). We then created a SQLite database that contains (among other things) a table that has the linearized form of the ontology. Annotations can be mapped directly to a term, or they can be inferred from any child term. Then given any EFO ontology label users can query the database to determine which, if any, GWAS catalog phenotypes have been mapped to that EFO term.

The data frame  `efo_df` has `r nrow(efo_df)` terms from the EFO ontology. Each row of this data frame has the CURIE identifier for the term (Subject), the EFO text description of the term (Object), the IRI for the term (this is a ULR linking to the EBI's EFO web pages), the disease location, if it was either reported or could be inferred from the ontology, the number of *direct* hits for that term and the number of *indirect* hits for that term, which we shall describe in more detail below.  We show the first 10 rows of the data frame.

```{r efodf}
datatable(efo_df[1:10,])
```


The GWAS catalog is quite big and as of 7/29/2023 there were 84589 studies reported. Each of those studies is associated with a published paper and there can be multiple studies associated with each paper. In addition to the information about the publication the studies have been assigned one or more 'study trait/disease' and each of these is mapped to one or more terms in the EFO (or related) ontologies. A major challenge for users is to find the set of relevant studies for some disease or set of diseases of interest. To date we are unaware of any tools that try to provide corpus level searching of the disease traits or EFO trait identifiers that use tools such as stemming, removal of stop words etc. In this package we have provided simple interface through the `corpustools` package. Our search strategy is as follows, for each EFO (and related ontologies) term we assemble the text description of that term, all ontology provided synonyms for that term and the 'study disease/traits' that were mapped directly to that ontology term. These represent the documents in our corpus and when searching it is the concatenation of those terms that is used to identify matches. Our function `search_features` performs that search and returns the set of EFO identifiers, plus some additional information about number of matches and what text was matched on.

To find the set of studies that corresponds to those EFO terms, we next apply the function `resources_annotated_with_term`. Which finds all the resources (studies in the GWAS catalog) that were annotated to a particular term. Now, the terms come from an ontology and the ontologies are typically consistent with a tree structure. The most specific terms are the leaves, and one moves up in the tree as terms become more general. For example, leukemia is the parent of nodes such as *acute leukemia* and *lymphoid leukemia*. While *lymphoid leukemia* is the parent of *T-cell leukemia*. When a user searches on the term *leukemia* they probably want to find all the terms not just the ones in the leaves. To manage that we use the structure in the ontology to support searching from a set of given nodes up the tree to find the more general nodes. The notion is that the relationship between a child-node and a parent is that there is either a 'is-a' relationship or a 'has-a' relationship. This can be made more formal, and in the accompanying paper for this project more details are given.

We will use the terminology that a study is mapped *directly* to an ontology term if the GWAS Catalog curators assigned that EFO term to the study. And a study is *mapped by inheritance* or *inherited* at an EFO (ontology) term if it was assigned *directly* to some child (descendant) of that EFO term. 

The set of study identifiers that come back from that search can then be used to query the annotated GWAS catalog. Studies can be retrieved by direct match between tag and GWAS phenotype, or study retrieval can be based on broader semantic matching using term relationships in the EFO.
Each study in the GWAS catalog identifies one or more replicated SNP associations. The user is required to select one SNP of interest, and then all catalog-replicated GWAS hits within a 1000kb window of this index SNP are extracted for visualization.

While helpful, we then have the challenge of how to help a researcher find an EFO label that corresponds to a topic they are interested in. To help solve that challenge we took all the EFO term labels and created a searchable corpus using the `corpustools` R package (<https://cran.r-project.org/web/packages/corpustools/index.html>) so that users can start with ordinary words and then find EFO terms that might be of interest. The output of this search can be accessed programmatically or we provide a conversion to a datatable that can be viewed, sorted and searched.

### How the corpus is created

Each EFO term, and more generally, any term from an ontology is turned into a *document* by appending the text description (label) for that term, any synonyms for that term that are provided by the ontology and also the text description of any phenotype that has been directly mapped to that EFO term. The rationale for the last part is that text descriptions that have been mapped to a specific EFO term are in essence also synonyms for that term. 

When searching the corpus for a match to input text string, all three of these sources are examined, the *object* which is the text label for the EFO term, the *synonyms* which are those provided by the ontology, and *matches* which are the phenotype labels for traits that have been mapped directly to that ontology term.  When searching we provide information on which of these three different sources had a match. In many cases a match will be found for more than one source.

## Understanding the corpus

We can examine the tCorpus and the data frame that are built from the underlying SQL tables that come with the `gwasCatSearch` database. First we look at the two components of the tCorpus object, `tokens` and `meta`.
```{r tCorpus}
dim(efo_tc$tokens)
colnames(efo_tc$tokens)
efo_tc$tokens[1,]
```
There are `r nrow(efo_tc$tokens)` places where a token is mapped to one of the three *fields*, the trait (subject), the synonyms or the matched traits.  When we search for some query phrase that generates `hits` and these are matches to the rows of the `efo_tc$tokens` table.

The meta-data tells us about the documents, there are `r nrow(efo_tc$meta)` documents, and the columns identify the ontology label, the IRI, disease location (when it is known) and the number of GWAS catelog traits that map either directly to the ontology label, or the number that are inherited (ie. they map to a more specific term).  This is essentially the same information as is contained in the `efo_df` data frame.
```{r tcMeta}
dim(efo_tc$meta)
colnames(efo_tc$meta)
efo_tc$meta[1,]
dim(efo_df)
efo_df[1,]
```
## Searching the corpus

In the first example below we search for any *document* that contains a match to either *granulo\** or *rheum\**. We named these two arguments **Granuloma** and **Rheumatic**. The `summary` function tells how many terms matched and in how many *documents*. We create a table using the `hitsasDT` function and render that using `datatable`. The output is searchable. Under the column labeled **Granuloma** are the actual words that were matched to *granulo\** and under the column labled **Rheumatic** are the words that matched to *rheum\**. The `corpustools` package provides a lot of functionality for mapping back to the *documents* so you can locate exactly where the match appears, and what word in the document actually matched the query. We have some examples below, but here we report simply the set of unique words that were matched, across all documents. This is just intended to be a summary of the results, and if you want to explore further you should refer to the `corpustools` documentation and vignettes.  We have built the corpus with the `split_sentences` argument set to `TRUE` so that we are able to identify which sentences have matches and we also report whether the match was in the subject, synonyms or matched trait labels. 

```{r}
hits = search_features(efo_tc, query = c('Granuloma# granulo*', 'Rheumatic# rheum*'))
hits = addField2Hits(hits, efo_tc)
summary(hits)
hits$hits[1:10,]
table(hits$hits$field)
```

We can see that there were `r nrow(hits)` hits.
We also see that most of the hits are in the `Matches` and the `Synonyms` fields, which makes some sense, as these fields will tend to have multiple entries, so there is more text to match. 

Next we show how to map from the hits object to the data.frame that contains the information about the ontology.  This can be done by obtaining the EFO ids for
terms you are interested in and then using those to select the appropriate rows in the `efo_df` object.  We show the values in the `Object` column of `efo_df` as these are the EFO text description for that EFO term.

```{r CheckHitsTrait}
## obtain the EFO ids for the hits in Object
testID = as.character(hits$hits$doc_id[hits$hits$field=="Object"])
length(testID)
head(efo_df[testID, "Object"])
```

The synonyms and the matched traits are not stored in the `efo_df` but you can obtain them using the `getSynonyms` function or the `getMatchedTraits` function, respectively. Notice that some of the synonyms are actually acronyms. This allows users to find features from acronyms. The CURIE identifier for the first element of `testID` is `r testID[1]` and we have seen above that its text description is "rheumatoid arthritis".  We obtain the synonyms for that term in the code below.
```{r GetSynonyms}
  getSynonyms(testID[1])
```
Where it is clear that these are not all really synonyms, some are the term itself, and at least one (rheumatic gout) seems to be in error, as this is an archaic term for gout, not for rheumatoid arthritis.

Similary we can look at the other matches, those are the names used for other traits in the GWAS catalog that map directly to the same ontological label.  These names are not unique (so there can be repeated values) and there can be spelling or punctuation differences. The function `getMatchedTraits` is vectorized and so returns a list of length equal to the number of provided CURIE symbols.

```{r matchedTraits}
mT = getMatchedTraits(testID[1])[[1]]
length(mT)
length(unique(mT))
```
In the code below we turn the hits into a searchable datatable.  The code restricts this to the first 100 rows in order to keep the examples small.
```{r makeDT}
hitsasDT = hits2DT(hits, efo_df, efo_tc)
datatable(hitsasDT[1:100,], escape=FALSE, rownames=FALSE)
```

Fairly complex search strategies can be employed, the interested reader is referred to the vignette for the `corpusTools` package as the syntax is quite unique to that package. In the next code chunk we show how an example using **and** where we search for any EFO labels that match to both *granulo\** and *rheum\**.

```{r searchAND}
ht2 = search_features(efo_tc, query = "granulo* AND rheum*")
summary(ht2)
```

There are `r summary(ht2)$documents` documents (EFO terms) that matched both, simultaneously.





Next we identify the GWAS catalog studies that were mapped directly to the EFO term EFO:0000095. The function `resources_annotated_with_term` returns a dataframe that contains information such as the GWAS catalog ID, the PubMed ID and so on. GWAS Catalog studies that map to more than one EFO term have the terms concatenated with comma separators. This does make some searching more complicated.

```{r EFO-directmapping}
##Direct mapping to that EFO term

dirMap = resources_annotated_with_term("EFO:0000095", include_subclasses=FALSE)
dim(dirMap)
dirMap[1,]
## look at a study with more than one mapping
idx = match("GCST008721", dirMap$STUDY.ACCESSION)
dirMap[idx,]

```

We see that there are `r nrow(dirMap)` terms that are directly annotated to EFO:0000095. The `DISEASE.TRAIT` column gives the name used for the trait in the paper or analysis being reported on, while the `MAPPED_TRAIT` column gives the text label for the EFO term.

Some of the phenotypes have been mapped to more than one EFO term. One example is the study GCST008721. The title of the accompanying paper is *Genetic overlap between autoimmune diseases and non-Hodgkin lymphoma subtypes*, which suggests why this particular study is associated with two different EFO terms. The paper reports on the genetic overlap between fairly different types of diseases.

## Searching for matches from GWAS Catalog hits.

Here we describe how to search for GWAS catalog hits that match a certain EFO identifier. For our example we use the EFO term [EFO:0007987](#0) which is labeled as *granulocyte count*. To do this we call the `resources_annotated_with_term` function. We provide the term identifier and then either ask only for the resources annotated specifically with the provided term (`ematch`) or for all those that either match directly, or that match to a child of the term provided (`allmatch`). There are `r efo_df["EFO:0007987", "Direct"]` that match directly and another `r efo_df["EFO:0007987", "Inherited"]` that match some child node and hence are inherited. We use a `datatable` so the reader can explore the first 20.

When looking at the matches it is helpful to know that there are three types of granulocytes, neutrophils, basophils and eosinophils. Which helps explain why a number of the matches are for these subtypes and not specifically for granulocytes.

```{r}
ematch = resources_annotated_with_term("EFO:0007987", include_subclasses=FALSE)
dim(ematch)
allmatch = resources_annotated_with_term("EFO:0007987", include_subclasses = TRUE)
dim(allmatch)
datatable(head(allmatch,n=20))
```

Now we might also want to find the papers that provided these results. For that we can
look at the PUBMEDID column in the `allmatch` data frame. Where we see that some papers such as PubMedID 27863252 have contributed multiple values. The title of that paper is
*The Allelic Landscape of Human Blood Cell Trait Variation and Links to Common Complex Disease*, which helps explain why the results have been separated into many different studies.

```{r pubmedforhits}
table(allmatch$PUBMEDID)
```

Now we can use the `variants_from_study` function to obtain information on the actual variants that were reported.  FIXME: we probably need to update this to use the DB tables or remove the DB tables and make the data more transparent.

```{r getvariants}
variants1 = variants_from_study(allmatch[1,1])
```
## Next Steps

Given the Study Accession identifiers we can then access the actual SNPs, the risk alleles get nearby genes and perform a variety of downstream analysis. For this step we currently use the `gwasrapidd` package, which directly queries the EBIs web resources for detailed information. This can lead to small differences between what it reports and the data we have used to build the corpus. The GWAS Catalog releases new data sets fairly regularly while we will rebuild the corpus only a few times per year.

```{r getSNPs}
library("gwasrapidd")
my_associations <- get_associations(study_id = allmatch[1,1])
slotNames(my_associations)
my_associations@entrez_ids
```

## Let's look at the autoimmune diseases.

In this example we are going to compare some of the results from the `gwasCatSearch` package with the results from the `gwasrapidd` package.

First we search the corpus for documents that contain both the word *autoimmune* and the word *disease*, the AND between them tells corpustools that both words need to be found in the same *document*. Recall that our documents are very short, they are just the text labels for the EFO terms, the synonyms and then the text descriptions of any phenotypes directly mapped to that EFO term. So most are much shorter than even one sentence.

The EFO term EFO:0005140 has the text label *autoimmune disease* so it should show up, and you can see in the data table that it does.

```{r autoimmune}

ht3 = search_features(efo_tc, query = "\"autoimmune AND disease\"")
dtxx = hits2DT(ht3, efo_df, efo_tc)
DT::datatable(dtxx, escape=FALSE, rownames=FALSE)
```

We can then take any of the EFO terms in that table and find the resources (in this case they are the papers, or publications, that contributed GWAS hits to the GWAS catalog) that have been associated with that EFO term. As noted previously these can be either mapped directly or indirectly (ie if they were mapped to a specific kind of autoimmune disease such as Type I diabetes, then they would also be Inherited at EFO:0005140).

```{r resourceAnnotation}
em = resources_annotated_with_term("EFO:0005140", include_subclasses = FALSE)
nrow(em)
```

In the above code we get only directly annotated matches and can see that there were `r nrow(em)` documents that were mapped directly to EFO:0005140. Below we get all of the matches, both direct and inherited, from our data table above we know that there should be `r dtxx["EFO:0005140", "Direct"]` documents mapped directly to EFO:0005140 and `r dtxx["EFO:0005140", "Inherited"]` documents that map to a term that is more specific than EFO:0005140, so `am` should have `r dtxx["EFO:0005140", "Direct"]+dtxx["EFO:0005140", "Inherited"]` rows.

```{r allmatches}
am = resources_annotated_with_term("EFO:0005140", include_subclasses = TRUE)
dim(am)
## let's see how many 
gg = grepl("*EFO:0005140*", am[,"MAPPED_TRAIT_CURIE"])
dim(am[gg,])

## their study accession numbers
am[gg, "STUDY.ACCESSION"]
```

We can compare with what the `gwasrapidd` vignette returns. One thing to notice is that even though the `study_ids` (our STUDY.ACCESSION values) are unique, the PubMed IDs are not. So the GWAS Catalog is supporting the idea that there could be multiple *studies* per paper. That seems like a good idea since some papers will report on GWAS for a variety of diseases, while others are focused on a single disease. When using the `gwasrapidd` package you need to get the text for the EFO term exactly right, there is no partial matching currently implemented.

```{r}
gwrdd = gwasrapidd::get_studies(efo_trait = 'autoimmune disease')
gwrdd@studies$study_id

gwrdd@publications$title

gwrdd@publications$pubmed_id

##make it diseases instead of disease and there are no matches
gwrdd2 = gwasrapidd::get_studies(efo_trait = 'autoimmune diseases')
gwrdd2

```

And a data table of all of them - just in case it is helpful.

```{r }
DT::datatable(am)
```

## More Corpus Tools functions

The `corpustools` package provides a large number of different tools for summarizing findings.  The vignette contained in the package gives a number of examples.  We want to explore a few of those here.

First we consider the notion of keywords in context (KWIC) and the function `get_kwic`.  Given a `tCorpus` and a set of hits this function returns information about just where the matches were. In the code below we first search for the term "pancrea*". The variable `kwD` contains information about the match, and just where in the document the match occurred. Users can specify the size of the context, and a variety of other features can be controlled by parameters to the function.  By default the matching word is wrapped in `<` and `>`, but these too can be specified by the user.

```{r KWIC}
htK = search_features(efo_tc, query = "pancrea*")
dtK = hits2DT(htK, efo_df, efo_tc)
DT::datatable(dtK, escape=FALSE, rownames=FALSE)
kwD = get_kwic(efo_tc, htK)
dim(kwD)
table(kwD$feature)
kwD[1,]
```

The `corpusTools` package can also do very complex NLP computations. A simple example is to use the feature association capabilities. This function will find common nearby features given either a query or a query hits object.

```{r FeatureA}
fa = feature_associations(efo_tc, 'feature', "chronic kidney disease")
head(fa)
```

## Description of the Database

The tools and process used to create a mapping based on the most recent GWAS Catalog obtained from <https://www.ebi.ac.uk/gwas/> are detailed in our GitHub repository <https://github.com/ccb-hms/GWASCatalogSearchDB> . This was achieved by combining the [EFO](https://www.ebi.ac.uk/efo/) ontology mappings specified in the GWAS Catalog metadata with tabular representations of ontology relationships---extracted from a [SemanticSQL](https://github.com/INCATools/semantic-sql) database representation of EFO---such that users can search for GWAS Catalog records by leveraging the EFO class hierarchy.

FIXME: below goes to the OpenGWAS search - this is not what we did for GWAS Catalog.

We mapped OpenGWAS phenotypes to EFO in the following way. The inputs to `text2term` were a table containing the OpenGWAS metadata from 2022-01-25 and the EFO ontology v3.43.0. We configured `text2term` to include only mappings with a score above our minimum threshold (`min_score=0.6`, in a `[0,1]` scale where `1` is an exact syntactic match), and to compute only the highest scored mapping for each trait in the metadata (`max_mappings=1`). We use the [TFIDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) mapper provided by `text2term` (`mapper=Mapper.TFIDF`), which computes TFIDF-based vector representations of traits and then uses cosine distance to determine how close each trait is to each ontology term (by considering ontology term labels and synonyms encoded in EFO). Finally we exclude terms that have been marked as deprecated (`excl_deprecated=True`) such that we only map to terms that are current and expected to be in EFO's future releases.

EFO contains terms and relationships between terms that exist in external ontologies such as MONDO, ChEBI, etc. Since our goal is to map phenotypes to appropriate terms in ontologies, if they exist, we further configured text2term to only map to terms from ontologies that describe phenotypes: EFO itself, the Monarch Disease Ontology (MONDO), the Human Phenotype Ontology (HPO), and the Orphanet Rare Disease Ontology (ORDO). To do this, we use the parameter `base_iris` in text2term which limits search to terms in the specified namespace(s), which we have set as follows: '<http://www.ebi.ac.uk/efo/>', '<http://purl.obolibrary.org/obo/MONDO>', '<http://purl.obolibrary.org/obo/HP>' and`ORDO` (<http://www.orpha.net/ORDO>).

### Challenges with this approach

The GWAS Catalog has mapped a number of protein abundance QTLs to the single EFO term Protein Measurement (EFO: ....), thus, with our approach there are about 5700 synonyms for this EFO term.  As a result it will show up often in searches.

The term "chronic kidney disease", which search for using `AND` between the words to ensure that we get matches only when all three words are present.
When we search the corpus we find tens of thousands of matches. Of these there are about 7,000 different documents - or EFO terms are matched. The vast majority of these EFO terms refer to the measurement of particular enzymes, or proteins, via GWAS. So, one might want to filter these into the set of terms that are types of protein measurements, lipid measurements etc.

```{r CKD}
ckdH = search_features(efo_tc, query = c('chronic AND kidney AND disease'))
ckdH = addField2Hits(ckdH, efo_tc)
summary(ckdH)
ckdH$hits[1:10,]
table(ckdH$hits$field)
length(unique(ckdH$hits$doc_id))
##so there are relatively few
am = resources_annotated_with_term("EFO:0000401", include_subclasses = FALSE)
dim(am)
table(am$PUBMEDID)
am2 = resources_annotated_with_term("EFO:0000401", include_subclasses = TRUE)
```
